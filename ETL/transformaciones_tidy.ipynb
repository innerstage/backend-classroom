{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones Tidy para los archivos fuente\n",
    "\n",
    "En este notebook mostraremos los pasos necesarios para llevar cada archivo al formato Tidy y luego unirlos bajo una lógica que siga siendo Tidy. Como primer paso, y para trabajar de forma más compacta, vamos a crear un comprensión de diccionario con DataFrames en vez de leer los archivos uno por uno, esta técnica puede facilitar la lectura del código y puede aumentar nuestra productividad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {i: pd.read_excel(\"data_source/chart{}.xlsx\".format(i)) for i in range(1,9)}\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones generales para todos los archivos\n",
    "\n",
    "Al observar el primer archivo en el análisis exploratorio anterior, nos damos cuenta de que posee tres columnas de variables (Región, Año del Censo y Acceso a TIC) y una columna con la observación (Valor Porcentaje). Para estandarizar llevaremos a cabo las siguientes operaciones:\n",
    "* Poner los nombres de región con mayúscula en la inicial y minúscula el resto del texto, usando el método title().\n",
    "* Añadiremos una columna que indique el origen de los datos (INEI o ENE).\n",
    "* Cambiar la columna de Censo para que utilice sólo el año como un número entero (menor espacio de almacenamiento en la base de datos), este año será usado en INEI o ENE.\n",
    "* Consideraremos una columna que indique la variable a medir, en este caso Acceso a TIC, y su valor (Accede, No accede), dejando la observación como \"porcentaje\".\n",
    "\n",
    "Estos serán los lineamientos generales para todos los archivos, en las tablas de ENE, el año siempre es 2017, justificamos esta decisión con un poco de información adicional del conjunto de datos:\n",
    "\n",
    "<img src=\"img/data_info.png\" style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transformaciones para chart1.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seleccionamos el DataFrame 1 en el diccionario, y utilizamos el método title() para modificar las regiones:\n",
    "df[1][\"region\"] = df[1][\"region\"].str.title() \n",
    "\n",
    "# Creamos una columna para el origen de los datos con un valor único:\n",
    "df[1][\"data_origin\"] = \"INEI\"\n",
    "\n",
    "# Cambiamos el nombre de la columna \"censo\" por \"year\", luego conservamos sólo los últimos cuatro dígitos del \n",
    "# texto (para extraer el año) y finalmente cambiamos el tipo de la columna para que sea numérica:\n",
    "df[1] = df[1].rename(columns={\"censo\":\"year\"})\n",
    "df[1][\"year\"] = df[1][\"year\"].str[-4:] # [-4:] indica que se toma desde el cuarto carácter contando desde el final hacia adelante.\n",
    "df[1][\"year\"] = df[1][\"year\"].astype(int) # Este paso se puede concatenar con el anterior usando .str[-4:].astype(int)\n",
    "\n",
    "# Creamos una columna para la variable \"acceso_tic\" y su respuesta, en esta etapa seguiremos una estrategia distinta\n",
    "# a cambiar el nombre, sólo crearemos una nueva columna copiando el contenido, y más adelante la descartaremos.\n",
    "df[1][\"variable\"] = \"Acceso a TIC\"\n",
    "df[1][\"response\"] = df[1][\"acceso_tic\"]\n",
    "\n",
    "# Cambiamos el nombre de la columna \"valor_porcentaje\" y nos aseguramos de que esté como tipo float.\n",
    "df[1] = df[1].rename(columns={\"valor_porcentaje\":\"percentage\"})\n",
    "# df[1][\"percentage\"] = df[1][\"percentage\"].astype(float) \n",
    "#La línea no es realmente necesaria, puedes verificar al final que ya está en tipo float, pero la dejo de ejemplo.\n",
    "\n",
    "# Seleccionamos sólo las columnas que queremos mantener\n",
    "df[1] = df[1][[\"region\", \"data_origin\", \"year\", \"variable\", \"response\", \"percentage\"]]\n",
    "\n",
    "df[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La limpieza de los archivos 2, 3 y 4 será similar en estructura, pasaremos a limpiar el archivo 5 y a diseñar una abstracción posteriormente.\n",
    "\n",
    "### 2. Transformaciones para chart5.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[5][\"region\"] = df[5][\"region\"].str.title()\n",
    "\n",
    "df[5][\"data_origin\"] = \"ENE\"\n",
    "\n",
    "df[5][\"year\"] = 2017 # En este caso no es necesario cambiar el tipo a int, la creamos de esa forma.\n",
    "\n",
    "df[5][\"variable\"] = \"Empleó equipos informáticos\"\n",
    "df[5][\"response\"] = df[5][\"empleo_equipos_informaticos\"]\n",
    "\n",
    "df[5] = df[5].rename(columns={\"valor_porcentaje\": \"percentage\"})\n",
    "\n",
    "df[5] = df[5][[\"region\", \"data_origin\", \"year\", \"variable\", \"response\", \"percentage\"]]\n",
    "\n",
    "df[5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Abstracción\n",
    "\n",
    "Ahora que tenemos una idea general de los pasos para transformar ambas clases de archivos, podemos establecer las diferencias:\n",
    "* El origen de datos será distinto para ambos tipos de archivo.\n",
    "* Requieren líneas distintas para obtener el año.\n",
    "* El bloque de variable/respuesta será distinto para cada archivo.\n",
    "\n",
    "Para diseñar una transformación más abstracta, podemos hacer uso de diccionarios, funciones y estructuras de control que nos ayuden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los archivos como al principio\n",
    "df = {i: pd.read_excel(\"data_source/chart{}.xlsx\".format(i)) for i in range(1,9)}\n",
    "\n",
    "# De esta forma, cuando escriba variable_dict[1] entregará el valor \"Acceso a TIC\", por ejemplo.\n",
    "variable_dict = { \n",
    "    1: \"Acceso a TIC\",\n",
    "    2: \"Acceso a Internet\",\n",
    "    3: \"Acceso a TV Cable\",\n",
    "    4: \"Tipo de Teléfono\",\n",
    "    5: \"Empleó Equipos Informáticos\",\n",
    "    6: \"Usó Internet\",\n",
    "    7: \"Usó Internet para buscar Productos y Servicios\",\n",
    "    8: \"Tuvo Problemas de Electricidad\"\n",
    "}\n",
    "\n",
    "# Esta función entrega la posición de la columna que tiene el valor de response que necesitamos.\n",
    "def get_response(i): \n",
    "    if i in [1,2,3,4]: # Si el archivo es de este tipo, el valor está en la tercera columna, o sea 2.\n",
    "        return 2\n",
    "    elif i in [5,6,7,8]: # Al saber que no hay más opciones para i, pudo ser \"else: return 1\", pero queda de ejemplo.\n",
    "        return 1\n",
    "# Hay otra forma incluso más corta de hacer esto, con una sola variable, pero dentro del ciclo que crearemos:\n",
    "# response_col = 2 if i in [1,2,3,4] else 1\n",
    "\n",
    "# Transformamos:\n",
    "for i in range(1,9):\n",
    "    df[i][\"region\"] = df[i][\"region\"].str.title()\n",
    "    \n",
    "    df[i][\"data_origin\"] = \"INEI\" if i in [1,2,3,4] else \"ENE\"\n",
    "    \n",
    "    if i in [1,2,3,4]:\n",
    "        df[i] = df[i].rename(columns={\"censo\":\"year\"})\n",
    "        df[i][\"year\"] = df[i][\"year\"].str[-4:] \n",
    "        df[i][\"year\"] = df[i][\"year\"].astype(int)\n",
    "    else:\n",
    "        df[i][\"year\"] = 2017\n",
    "        \n",
    "    df[i][\"variable\"] = variable_dict[i]\n",
    "    df[i][\"response\"] = df[i].iloc[:, get_response(i)]\n",
    "    \n",
    "    df[i] = df[i].rename(columns={\"valor_porcentaje\": \"percentage\"})\n",
    "    \n",
    "    df[i] = df[i][[\"region\", \"data_origin\", \"year\", \"variable\", \"response\", \"percentage\"]]\n",
    "    \n",
    "# Y finalmente concatenamos todas las DataFrames, para eso creamos una lista con ellas, sacándolas del diccionario:\n",
    "df_list = [df[i] for i in range(1,9)]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro conjunto de datos ya se encuentra en formato Tidy. Adicionalmente podemos analizar las columnas generadas para asegurarnos de que el archivo final está bien.\n",
    "\n",
    "### 4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deberíamos tener 25 regiones:\n",
    "print(\"Regiones:\", len(df[\"region\"].unique()), \"\\n\")\n",
    "\n",
    "# Dos valores únicos para \"data_origin\" y \"year\"\n",
    "print(df[\"data_origin\"].value_counts(dropna=False), \"\\n\")\n",
    "print(df[\"year\"].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "# 8 valores distintos para \"variable\"\n",
    "print(df[\"variable\"].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "# Valores distintos para \"response\", el resultado nos muestra que hay valores repetidos pero está bien.\n",
    "# En el pipeline de Bamboo sería recomendable convertir esta respuesta binaria en 0 y 1.\n",
    "print(df[\"response\"].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "# Revisamos si algún porcentaje se escapa del intervalo [0,1]:\n",
    "print(df[(df[\"percentage\"]<=0) | (df[\"percentage\"]>=1)], \"\\n\")\n",
    "\n",
    "# Y por último chequear que no hay valores nulos en ninguna columna:\n",
    "print(df.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para guardar nuestro progreso hasta este punto, crearemos un archivo `.csv` que tenga todos los datos en formato tidy. En el pipeline real no realizaremos este paso, por lo tanto el archivo será almacenado en la carpeta `data_temp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicamos index=False para que los índices del DataFrame no sean guardados en el archivo.\n",
    "# quoting indica qué comillas (quotes) tendrán ciertos tipos de columna, importamos este estilo desde \n",
    "# la librería \"csv\" para solamente poner comillas en los valores que no sean numéricos.\n",
    "df.to_csv(\"data_temp/tidy_file.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto concluimos nuestras transformaciones, en la siguiente sección estudiaremos el modelo relacional."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
